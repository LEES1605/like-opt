# âš¡ Like-Opt - Performance Optimization Plan

## ğŸ“‹ ê°œìš”

**ëª©ì **: Like-Opt ì‹œìŠ¤í…œì˜ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±ì„ ìœ„í•œ ì¢…í•© ìµœì í™” ì „ëµ

**ëª©í‘œ**: ì‘ë‹µ ì†ë„ 50% í–¥ìƒ, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 30% ê°ì†Œ, ë™ì‹œ ì‚¬ìš©ì ìˆ˜ 10ë°° ì¦ê°€
**ë²”ìœ„**: ë°±ì—”ë“œ API, í”„ë¡ íŠ¸ì—”ë“œ UI, ë°ì´í„°ë² ì´ìŠ¤, ë„¤íŠ¸ì›Œí¬, ìºì‹±

---

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” ëª©í‘œ

### 1. ì‘ë‹µ ì†ë„ ëª©í‘œ
- ğŸš€ **API ì‘ë‹µ**: < 200ms (í‰ê· ), < 500ms (95th percentile)
- âš¡ **í˜ì´ì§€ ë¡œë”©**: < 1ì´ˆ (ì´ˆê¸° ë¡œë”©), < 500ms (SPA ë„¤ë¹„ê²Œì´ì…˜)
- ğŸ“¡ **AI ì‘ë‹µ**: < 2ì´ˆ (ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘), < 5ì´ˆ (ì™„ì „ ì‘ë‹µ)
- ğŸ”„ **ê²€ìƒ‰ ì„±ëŠ¥**: < 100ms (RAG ê²€ìƒ‰)

### 2. ì²˜ë¦¬ëŸ‰ ëª©í‘œ
- ğŸ“Š **ë™ì‹œ ì‚¬ìš©ì**: 1000ëª… â†’ 10000ëª…
- ğŸ”„ **ìš”ì²­ ì²˜ë¦¬ëŸ‰**: 100 req/s â†’ 1000 req/s
- ğŸ’¾ **ë©”ëª¨ë¦¬ íš¨ìœ¨**: 50% ê°ì†Œ
- ğŸ“ˆ **CPU íš¨ìœ¨**: 30% ê°œì„ 

### 3. í™•ì¥ì„± ëª©í‘œ
- ğŸ”§ **ìˆ˜í‰ í™•ì¥**: ë¬´ì¤‘ë‹¨ ìŠ¤ì¼€ì¼ë§
- ğŸ“¦ **ë¦¬ì†ŒìŠ¤ ìµœì í™”**: ìë™ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
- ğŸŒ **CDN í™œìš©**: ê¸€ë¡œë²Œ ì½˜í…ì¸  ì „ì†¡
- âš¡ **ìºì‹± ì „ëµ**: 80% ìºì‹œ íˆíŠ¸ìœ¨

---

## ğŸ—ï¸ ì„±ëŠ¥ ì•„í‚¤í…ì²˜

### 1. ì „ì²´ ì„±ëŠ¥ ì•„í‚¤í…ì²˜
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CDN (CloudFront)                        â”‚
â”‚                    Static Assets                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Load Balancer (Nginx)                       â”‚
â”‚                SSL Termination + Compression               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Application Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Flask App â”‚  â”‚   Flask App â”‚  â”‚   Flask App â”‚        â”‚
â”‚  â”‚  (Gunicorn) â”‚  â”‚  (Gunicorn) â”‚  â”‚  (Gunicorn) â”‚        â”‚
â”‚  â”‚  4 Workers  â”‚  â”‚  4 Workers  â”‚  â”‚  4 Workers  â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Cache Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Redis     â”‚  â”‚   Memcached â”‚  â”‚   CDN       â”‚        â”‚
â”‚  â”‚  (Sessions) â”‚  â”‚  (Objects)  â”‚  â”‚  (Assets)   â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Database Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   ChromaDB  â”‚  â”‚   Vector    â”‚  â”‚   File      â”‚        â”‚
â”‚  â”‚  (Vectors)  â”‚  â”‚  Index      â”‚  â”‚  (Storage)  â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Performance Dashboard                    â”‚
â”‚                                                             â”‚
â”‚  ğŸ“Š Response Time    ğŸ“ˆ Throughput    ğŸ’¾ Memory Usage     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   150ms     â”‚    â”‚  850 req/s  â”‚   â”‚   2.1 GB    â”‚     â”‚
â”‚  â”‚  (Average)  â”‚    â”‚  (Current)  â”‚   â”‚   (Peak)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚  ğŸ”„ Cache Hit Rate  ğŸš€ Page Load     âš¡ API Latency        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚    87%      â”‚    â”‚   0.8s      â”‚   â”‚   180ms     â”‚     â”‚
â”‚  â”‚  (Hit Rate) â”‚    â”‚  (Average)  â”‚   â”‚  (P95)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ ë°±ì—”ë“œ ì„±ëŠ¥ ìµœì í™”

### 1. Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ìµœì í™”

#### 1.1 Gunicorn ì„¤ì • ìµœì í™”
```python
# gunicorn_config.py
import multiprocessing
import os

# ì„œë²„ ì†Œì¼“
bind = "0.0.0.0:5000"
backlog = 2048

# Worker í”„ë¡œì„¸ìŠ¤
workers = multiprocessing.cpu_count() * 2 + 1
worker_class = "gevent"
worker_connections = 1000
max_requests = 1000
max_requests_jitter = 100

# íƒ€ì„ì•„ì›ƒ ì„¤ì •
timeout = 120
keepalive = 5
graceful_timeout = 30

# ë¡œê¹…
accesslog = "/var/log/gunicorn/access.log"
errorlog = "/var/log/gunicorn/error.log"
loglevel = "info"
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# ì„±ëŠ¥ ìµœì í™”
preload_app = True
worker_tmp_dir = "/dev/shm"

# í”„ë¡œì„¸ìŠ¤ ì´ë¦„
proc_name = "like-opt"

# ë³´ì•ˆ
limit_request_line = 4096
limit_request_fields = 100
limit_request_field_size = 8192

# í™˜ê²½ ë³€ìˆ˜
raw_env = [
    'PYTHONPATH=/app',
    'FLASK_ENV=production'
]
```

#### 1.2 Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ìµœì í™”
```python
# backend/app/__init__.py (ìµœì í™”ëœ ë²„ì „)
import os
from pathlib import Path
from flask import Flask, jsonify, request
from flask_session import Session
from flask_compress import Compress
from flask_caching import Cache
import redis

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).resolve().parents[3]

def create_app():
    """ìµœì í™”ëœ Flask ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ©í† ë¦¬"""
    app = Flask(
        __name__,
        template_folder=str(project_root / 'frontend' / 'templates'),
        static_folder=str(project_root / 'frontend' / 'static')
    )

    # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
    app.config.update(
        # ê¸°ë³¸ ì„¤ì •
        SECRET_KEY=os.getenv('SECRET_KEY', 'like-opt-secret-key-2024'),
        
        # ì„¸ì…˜ ìµœì í™”
        SESSION_TYPE='redis',
        SESSION_REDIS=redis.from_url(os.getenv('REDIS_URL', 'redis://localhost:6379/0')),
        SESSION_PERMANENT=True,
        SESSION_USE_SIGNER=True,
        SESSION_KEY_PREFIX='likeopt:session:',
        SESSION_COOKIE_HTTPONLY=True,
        SESSION_COOKIE_SAMESITE='Lax',
        SESSION_COOKIE_SECURE=os.getenv('SESSION_COOKIE_SECURE', 'False').lower() == 'true',
        PERMANENT_SESSION_LIFETIME=int(os.getenv('PERMANENT_SESSION_LIFETIME', 86400)),
        
        # ì••ì¶• ì„¤ì •
        COMPRESS_MIMETYPES=[
            'text/html', 'text/css', 'text/xml', 'text/javascript',
            'application/json', 'application/javascript', 'application/xml+rss',
            'application/atom+xml', 'image/svg+xml'
        ],
        COMPRESS_LEVEL=6,
        COMPRESS_MIN_SIZE=500,
        
        # ìºì‹± ì„¤ì •
        CACHE_TYPE='redis',
        CACHE_REDIS_URL=os.getenv('REDIS_URL', 'redis://localhost:6379/1'),
        CACHE_DEFAULT_TIMEOUT=300,
        CACHE_KEY_PREFIX='likeopt:cache:',
        
        # íŒŒì¼ ì—…ë¡œë“œ ìµœì í™”
        MAX_CONTENT_LENGTH=int(os.getenv('MAX_CONTENT_LENGTH', 16 * 1024 * 1024)),
        
        # ê¸°íƒ€ ì„±ëŠ¥ ì„¤ì •
        JSON_SORT_KEYS=False,
        JSONIFY_PRETTYPRINT_REGULAR=False,
        WTF_CSRF_ENABLED=False,
    )

    # í™•ì¥ ì´ˆê¸°í™”
    Session(app)
    Compress(app)
    Cache(app)
    
    # ë¸”ë£¨í”„ë¦°íŠ¸ ë“±ë¡
    register_blueprints(app)
    
    # ì—ëŸ¬ í•¸ë“¤ëŸ¬ ë“±ë¡
    register_error_handlers(app)
    
    # ì„±ëŠ¥ ë¯¸ë“¤ì›¨ì–´ ë“±ë¡
    register_performance_middleware(app)
    
    return app

def register_performance_middleware(app):
    """ì„±ëŠ¥ ìµœì í™” ë¯¸ë“¤ì›¨ì–´ ë“±ë¡"""
    
    @app.before_request
    def before_request():
        """ìš”ì²­ ì „ ì²˜ë¦¬"""
        # ìš”ì²­ ID ìƒì„± (ë¡œê¹…ìš©)
        request.request_id = str(uuid.uuid4())
        
        # ìš”ì²­ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        request.start_time = time.time()
    
    @app.after_request
    def after_request(response):
        """ì‘ë‹µ í›„ ì²˜ë¦¬"""
        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        if hasattr(request, 'start_time'):
            duration = time.time() - request.start_time
            response.headers['X-Response-Time'] = f"{duration:.3f}s"
        
        # ìºì‹œ í—¤ë” ì„¤ì •
        if request.endpoint in ['static', 'api.health']:
            response.headers['Cache-Control'] = 'public, max-age=31536000'  # 1ë…„
        elif request.endpoint in ['api.chat']:
            response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        
        # CORS í—¤ë”
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        
        return response
    
    @app.teardown_request
    def teardown_request(exception):
        """ìš”ì²­ ì •ë¦¬"""
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë¡œì§
        pass
```

#### 1.3 ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
```python
# backend/app/services/optimized_rag_service.py
import asyncio
import aiohttp
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor
import redis
import json

class OptimizedRAGService:
    """ìµœì í™”ëœ RAG ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.redis_client = redis.from_url(os.getenv('REDIS_URL', 'redis://localhost:6379/2'))
        self.cache_ttl = 3600  # 1ì‹œê°„
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        
        # ë²¡í„° ì¸ë±ìŠ¤ ìºì‹œ
        self._vector_index_cache = {}
        self._chunks_cache = {}
    
    @lru_cache(maxsize=1000)
    def _get_cached_chunks(self, query_hash):
        """ìºì‹œëœ ì²­í¬ ì¡°íšŒ"""
        cached = self.redis_client.get(f"chunks:{query_hash}")
        if cached:
            return json.loads(cached)
        return None
    
    def _cache_chunks(self, query_hash, chunks):
        """ì²­í¬ ìºì‹œ ì €ì¥"""
        self.redis_client.setex(
            f"chunks:{query_hash}",
            self.cache_ttl,
            json.dumps(chunks)
        )
    
    async def search_async(self, query: str, top_k: int = 5) -> List[RAGResult]:
        """ë¹„ë™ê¸° ê²€ìƒ‰"""
        query_hash = hashlib.md5(query.encode()).hexdigest()
        
        # ìºì‹œ í™•ì¸
        cached_results = self._get_cached_chunks(query_hash)
        if cached_results:
            return [RAGResult.from_dict(r) for r in cached_results]
        
        # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
        tasks = [
            self._bm25_search(query, top_k),
            self._vector_search(query, top_k),
            self._hybrid_search(query, top_k)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ìµœì  ê²°ê³¼ ì„ íƒ
        best_results = self._merge_results(results)
        
        # ê²°ê³¼ ìºì‹œ
        self._cache_chunks(query_hash, [r.to_dict() for r in best_results])
        
        return best_results
    
    async def _bm25_search(self, query: str, top_k: int) -> List[RAGResult]:
        """BM25 ë¹„ë™ê¸° ê²€ìƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.thread_pool,
            self._bm25_search_sync,
            query, top_k
        )
    
    async def _vector_search(self, query: str, top_k: int) -> List[RAGResult]:
        """ë²¡í„° ë¹„ë™ê¸° ê²€ìƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.thread_pool,
            self._vector_search_sync,
            query, top_k
        )
    
    def _merge_results(self, results: List[List[RAGResult]]) -> List[RAGResult]:
        """ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ë° ìµœì í™”"""
        merged = {}
        
        for result_list in results:
            if isinstance(result_list, Exception):
                continue
                
            for result in result_list:
                key = f"{result.doc_id}:{result.chunk_id}"
                if key in merged:
                    # ì ìˆ˜ í‰ê·  ê³„ì‚°
                    merged[key].score = (merged[key].score + result.score) / 2
                else:
                    merged[key] = result
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_results = sorted(merged.values(), key=lambda x: x.score, reverse=True)
        return sorted_results[:top_k]
```

### 2. ìºì‹± ì „ëµ

#### 2.1 ë‹¤ì¸µ ìºì‹± ì‹œìŠ¤í…œ
```python
# backend/app/cache/multi_layer_cache.py
import redis
import json
import pickle
from typing import Any, Optional, Union
from functools import wraps
import time

class MultiLayerCache:
    """ë‹¤ì¸µ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # L1: ë©”ëª¨ë¦¬ ìºì‹œ (LRU)
        self.memory_cache = {}
        self.memory_cache_order = []
        self.memory_cache_max_size = 1000
        
        # L2: Redis ìºì‹œ
        self.redis_client = redis.from_url(os.getenv('REDIS_URL', 'redis://localhost:6379/3'))
        
        # L3: ë””ìŠ¤í¬ ìºì‹œ (í° ë°ì´í„°ìš©)
        self.disk_cache_dir = Path('/tmp/likeopt_cache')
        self.disk_cache_dir.mkdir(exist_ok=True)
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        # L1: ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        if key in self.memory_cache:
            self._update_memory_cache_order(key)
            return self.memory_cache[key]
        
        # L2: Redis ìºì‹œ í™•ì¸
        redis_data = self.redis_client.get(f"cache:{key}")
        if redis_data:
            try:
                data = pickle.loads(redis_data)
                self._set_memory_cache(key, data)
                return data
            except Exception:
                pass
        
        # L3: ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
        disk_path = self.disk_cache_dir / f"{hash(key)}.cache"
        if disk_path.exists():
            try:
                with open(disk_path, 'rb') as f:
                    data = pickle.load(f)
                self._set_memory_cache(key, data)
                return data
            except Exception:
                pass
        
        return None
    
    def set(self, key: str, value: Any, ttl: int = 3600, layer: str = 'auto') -> None:
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        if layer in ['auto', 'memory']:
            self._set_memory_cache(key, value)
        
        if layer in ['auto', 'redis'] and not isinstance(value, (str, int, float, bool, list, dict)):
            # ë³µì¡í•œ ê°ì²´ëŠ” Redisì— ì €ì¥
            try:
                self.redis_client.setex(f"cache:{key}", ttl, pickle.dumps(value))
            except Exception:
                pass
        
        if layer in ['auto', 'disk'] and len(str(value)) > 1024 * 1024:  # 1MB ì´ìƒ
            # í° ë°ì´í„°ëŠ” ë””ìŠ¤í¬ì— ì €ì¥
            disk_path = self.disk_cache_dir / f"{hash(key)}.cache"
            try:
                with open(disk_path, 'wb') as f:
                    pickle.dump(value, f)
            except Exception:
                pass
    
    def _set_memory_cache(self, key: str, value: Any) -> None:
        """ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥"""
        if len(self.memory_cache) >= self.memory_cache_max_size:
            # LRU ì œê±°
            oldest_key = self.memory_cache_order.pop(0)
            del self.memory_cache[oldest_key]
        
        self.memory_cache[key] = value
        self._update_memory_cache_order(key)
    
    def _update_memory_cache_order(self, key: str) -> None:
        """ë©”ëª¨ë¦¬ ìºì‹œ ìˆœì„œ ì—…ë°ì´íŠ¸"""
        if key in self.memory_cache_order:
            self.memory_cache_order.remove(key)
        self.memory_cache_order.append(key)

# ìºì‹œ ë°ì½”ë ˆì´í„°
def cached(ttl: int = 3600, layer: str = 'auto'):
    """ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # ìºì‹œì—ì„œ ì¡°íšŒ
            cache = MultiLayerCache()
            cached_result = cache.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # í•¨ìˆ˜ ì‹¤í–‰
            result = func(*args, **kwargs)
            
            # ê²°ê³¼ ìºì‹œ
            cache.set(cache_key, result, ttl, layer)
            
            return result
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@cached(ttl=1800, layer='redis')
def get_ai_response(prompt: str, model: str) -> str:
    """AI ì‘ë‹µ ìºì‹±"""
    # AI API í˜¸ì¶œ ë¡œì§
    pass

@cached(ttl=3600, layer='memory')
def get_rag_context(query: str) -> str:
    """RAG ì»¨í…ìŠ¤íŠ¸ ìºì‹±"""
    # RAG ê²€ìƒ‰ ë¡œì§
    pass
```

#### 2.2 API ì‘ë‹µ ìºì‹±
```python
# backend/app/api/cached_endpoints.py
from flask import request, jsonify
from flask_caching import Cache
from functools import wraps
import hashlib

cache = Cache()

def api_cache(timeout=300, key_prefix='api'):
    """API ì‘ë‹µ ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{key_prefix}:{request.endpoint}:{hashlib.md5(str(request.args).encode()).hexdigest()}"
            
            # ìºì‹œì—ì„œ ì¡°íšŒ
            cached_result = cache.get(cache_key)
            if cached_result is not None:
                return jsonify(cached_result)
            
            # API ì‹¤í–‰
            result = f(*args, **kwargs)
            
            # ê²°ê³¼ ìºì‹œ (JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ê²½ìš°ë§Œ)
            if isinstance(result, (dict, list, str, int, float, bool)):
                cache.set(cache_key, result, timeout=timeout)
            
            return result
        return decorated_function
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@api_bp.route('/conversation', methods=['GET'])
@api_cache(timeout=60)  # 1ë¶„ ìºì‹œ
def get_conversation():
    """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ (ìºì‹± ì ìš©)"""
    conversation = chat_service.get_conversation()
    return [msg.to_dict() for msg in conversation]

@api_bp.route('/indexing/status', methods=['GET'])
@api_cache(timeout=30)  # 30ì´ˆ ìºì‹œ
def get_indexing_status():
    """ì¸ë±ì‹± ìƒíƒœ ì¡°íšŒ (ìºì‹± ì ìš©)"""
    return indexing_service.get_indexing_status()
```

---

## ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ ì„±ëŠ¥ ìµœì í™”

### 1. ë²ˆë“¤ ìµœì í™”

#### 1.1 Webpack ì„¤ì • ìµœì í™”
```javascript
// frontend/webpack.config.js
const path = require('path');
const MiniCssExtractPlugin = require('mini-css-extract-plugin');
const TerserPlugin = require('terser-webpack-plugin');
const CompressionPlugin = require('compression-webpack-plugin');
const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');

module.exports = (env, argv) => {
  const isProduction = argv.mode === 'production';
  
  return {
    entry: './src/main.js',
    output: {
      path: path.resolve(__dirname, 'dist'),
      filename: isProduction ? '[name].[contenthash].js' : '[name].js',
      chunkFilename: isProduction ? '[name].[contenthash].chunk.js' : '[name].chunk.js',
      clean: true,
      publicPath: '/static/',
    },
    
    optimization: {
      minimize: isProduction,
      minimizer: [
        new TerserPlugin({
          terserOptions: {
            compress: {
              drop_console: isProduction,
              drop_debugger: isProduction,
            },
            mangle: true,
          },
          extractComments: false,
        }),
      ],
      
      // ì½”ë“œ ë¶„í• 
      splitChunks: {
        chunks: 'all',
        cacheGroups: {
          vendor: {
            test: /[\\/]node_modules[\\/]/,
            name: 'vendors',
            chunks: 'all',
            priority: 10,
          },
          common: {
            name: 'common',
            minChunks: 2,
            chunks: 'all',
            priority: 5,
            reuseExistingChunk: true,
          },
        },
      },
      
      // ëŸ°íƒ€ì„ ì²­í¬ ë¶„ë¦¬
      runtimeChunk: 'single',
      
      // ëª¨ë“ˆ ID ì•ˆì •í™”
      moduleIds: 'deterministic',
    },
    
    module: {
      rules: [
        {
          test: /\.js$/,
          exclude: /node_modules/,
          use: {
            loader: 'babel-loader',
            options: {
              presets: ['@babel/preset-env'],
              plugins: [
                '@babel/plugin-transform-runtime',
                '@babel/plugin-syntax-dynamic-import',
              ],
            },
          },
        },
        {
          test: /\.css$/,
          use: [
            isProduction ? MiniCssExtractPlugin.loader : 'style-loader',
            'css-loader',
            {
              loader: 'postcss-loader',
              options: {
                postcssOptions: {
                  plugins: [
                    ['autoprefixer'],
                    ['cssnano', { preset: 'default' }],
                  ],
                },
              },
            },
          ],
        },
      ],
    },
    
    plugins: [
      new MiniCssExtractPlugin({
        filename: isProduction ? '[name].[contenthash].css' : '[name].css',
        chunkFilename: isProduction ? '[name].[contenthash].chunk.css' : '[name].chunk.css',
      }),
      
      // Gzip ì••ì¶•
      new CompressionPlugin({
        algorithm: 'gzip',
        test: /\.(js|css|html|svg)$/,
        threshold: 8192,
        minRatio: 0.8,
      }),
      
      // ë²ˆë“¤ ë¶„ì„ (ê°œë°œ ì‹œì—ë§Œ)
      ...(isProduction ? [] : [new BundleAnalyzerPlugin()]),
    ],
    
    // ì„±ëŠ¥ íŒíŠ¸
    performance: {
      hints: isProduction ? 'warning' : false,
      maxEntrypointSize: 512000,
      maxAssetSize: 512000,
    },
    
    // ê°œë°œ ì„œë²„ ì„¤ì •
    devServer: {
      static: {
        directory: path.join(__dirname, 'public'),
      },
      compress: true,
      port: 3000,
      hot: true,
      historyApiFallback: true,
    },
  };
};
```

#### 1.2 ë™ì  ì„í¬íŠ¸ ë° ì§€ì—° ë¡œë”©
```javascript
// frontend/src/router/lazyLoader.js
export class LazyLoader {
  constructor() {
    this.loadedModules = new Map();
    this.loadingPromises = new Map();
  }

  async loadComponent(modulePath) {
    // ì´ë¯¸ ë¡œë“œëœ ëª¨ë“ˆ í™•ì¸
    if (this.loadedModules.has(modulePath)) {
      return this.loadedModules.get(modulePath);
    }

    // ë¡œë”© ì¤‘ì¸ ëª¨ë“ˆ í™•ì¸
    if (this.loadingPromises.has(modulePath)) {
      return this.loadingPromises.get(modulePath);
    }

    // ëª¨ë“ˆ ë¡œë”© ì‹œì‘
    const loadingPromise = import(modulePath).then(module => {
      this.loadedModules.set(modulePath, module);
      this.loadingPromises.delete(modulePath);
      return module;
    }).catch(error => {
      this.loadingPromises.delete(modulePath);
      throw error;
    });

    this.loadingPromises.set(modulePath, loadingPromise);
    return loadingPromise;
  }

  // ì»´í¬ë„ŒíŠ¸ ì§€ì—° ë¡œë”©
  async loadPageComponent(pageName) {
    const modulePath = `../pages/${pageName}.js`;
    return this.loadComponent(modulePath);
  }

  // ì„œë¹„ìŠ¤ ì§€ì—° ë¡œë”©
  async loadService(serviceName) {
    const modulePath = `../services/${serviceName}.js`;
    return this.loadComponent(modulePath);
  }
}

export const lazyLoader = new LazyLoader();

// ì‚¬ìš© ì˜ˆì‹œ
// frontend/src/router/router.js
export class Router {
  constructor() {
    this.routes = new Map();
    this.currentRoute = null;
  }

  async navigate(path) {
    // ë¼ìš°íŠ¸ ë§¤ì¹­
    const route = this.matchRoute(path);
    if (!route) {
      throw new Error(`Route not found: ${path}`);
    }

    // ì»´í¬ë„ŒíŠ¸ ì§€ì—° ë¡œë”©
    const { default: Component } = await lazyLoader.loadPageComponent(route.component);
    
    // ì»´í¬ë„ŒíŠ¸ ë Œë”ë§
    this.renderComponent(Component, route.props);
  }

  matchRoute(path) {
    for (const [pattern, route] of this.routes) {
      if (pattern.test(path)) {
        return route;
      }
    }
    return null;
  }

  renderComponent(Component, props = {}) {
    const container = document.getElementById('app');
    container.innerHTML = '';
    
    const component = new Component(props);
    container.appendChild(component.render());
  }
}
```

### 2. ì´ë¯¸ì§€ ë° ë¦¬ì†ŒìŠ¤ ìµœì í™”

#### 2.1 ì´ë¯¸ì§€ ì§€ì—° ë¡œë”©
```javascript
// frontend/src/utils/imageOptimizer.js
export class ImageOptimizer {
  constructor() {
    this.observer = null;
    this.initIntersectionObserver();
  }

  initIntersectionObserver() {
    this.observer = new IntersectionObserver(
      (entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            this.loadImage(entry.target);
            this.observer.unobserve(entry.target);
          }
        });
      },
      {
        rootMargin: '50px',
        threshold: 0.1
      }
    );
  }

  loadImage(img) {
    const src = img.dataset.src;
    if (!src) return;

    // ì´ë¯¸ì§€ ë¡œë”©
    const imageLoader = new Image();
    imageLoader.onload = () => {
      img.src = src;
      img.classList.add('loaded');
    };
    imageLoader.onerror = () => {
      img.classList.add('error');
    };
    imageLoader.src = src;
  }

  observeImage(img) {
    this.observer.observe(img);
  }

  // WebP ì§€ì› í™•ì¸
  supportsWebP() {
    const canvas = document.createElement('canvas');
    canvas.width = 1;
    canvas.height = 1;
    return canvas.toDataURL('image/webp').indexOf('data:image/webp') === 0;
  }

  // ìµœì í™”ëœ ì´ë¯¸ì§€ URL ìƒì„±
  getOptimizedImageUrl(originalUrl, options = {}) {
    const {
      width = null,
      height = null,
      quality = 80,
      format = 'auto'
    } = options;

    const params = new URLSearchParams();
    
    if (width) params.set('w', width);
    if (height) params.set('h', height);
    if (quality) params.set('q', quality);
    
    if (format === 'auto') {
      params.set('f', this.supportsWebP() ? 'webp' : 'jpg');
    } else {
      params.set('f', format);
    }

    return `${originalUrl}?${params.toString()}`;
  }
}

export const imageOptimizer = new ImageOptimizer();

// ì‚¬ìš© ì˜ˆì‹œ
document.addEventListener('DOMContentLoaded', () => {
  const images = document.querySelectorAll('img[data-src]');
  images.forEach(img => imageOptimizer.observeImage(img));
});
```

#### 2.2 ë¦¬ì†ŒìŠ¤ í”„ë¦¬ë¡œë”©
```javascript
// frontend/src/utils/resourcePreloader.js
export class ResourcePreloader {
  constructor() {
    this.preloadedResources = new Set();
    this.preloadQueue = [];
    this.isPreloading = false;
  }

  // ë¦¬ì†ŒìŠ¤ í”„ë¦¬ë¡œë”©
  async preloadResource(url, type = 'script') {
    if (this.preloadedResources.has(url)) {
      return Promise.resolve();
    }

    return new Promise((resolve, reject) => {
      const element = this.createPreloadElement(url, type);
      
      element.onload = () => {
        this.preloadedResources.add(url);
        resolve();
      };
      
      element.onerror = () => {
        reject(new Error(`Failed to preload: ${url}`));
      };

      document.head.appendChild(element);
    });
  }

  createPreloadElement(url, type) {
    const element = document.createElement('link');
    element.rel = 'preload';
    element.href = url;

    switch (type) {
      case 'script':
        element.as = 'script';
        break;
      case 'style':
        element.as = 'style';
        break;
      case 'font':
        element.as = 'font';
        element.crossOrigin = 'anonymous';
        break;
      case 'image':
        element.as = 'image';
        break;
      default:
        element.as = type;
    }

    return element;
  }

  // í˜ì´ì§€ ë¦¬ì†ŒìŠ¤ í”„ë¦¬ë¡œë”©
  async preloadPageResources(pageName) {
    const resources = this.getPageResources(pageName);
    
    const preloadPromises = resources.map(({ url, type }) =>
      this.preloadResource(url, type)
    );

    try {
      await Promise.all(preloadPromises);
      console.log(`Preloaded resources for page: ${pageName}`);
    } catch (error) {
      console.warn('Some resources failed to preload:', error);
    }
  }

  getPageResources(pageName) {
    const resourceMap = {
      'chat': [
        { url: '/static/js/chat.js', type: 'script' },
        { url: '/static/css/chat.css', type: 'style' },
      ],
      'admin': [
        { url: '/static/js/admin.js', type: 'script' },
        { url: '/static/css/admin.css', type: 'style' },
      ],
    };

    return resourceMap[pageName] || [];
  }

  // ì¤‘ìš” ë¦¬ì†ŒìŠ¤ ìš°ì„  í”„ë¦¬ë¡œë”©
  async preloadCriticalResources() {
    const criticalResources = [
      { url: '/static/css/critical.css', type: 'style' },
      { url: '/static/js/main.js', type: 'script' },
    ];

    await Promise.all(
      criticalResources.map(({ url, type }) =>
        this.preloadResource(url, type)
      )
    );
  }
}

export const resourcePreloader = new ResourcePreloader();
```

### 3. ìƒíƒœ ê´€ë¦¬ ìµœì í™”

#### 3.1 íš¨ìœ¨ì ì¸ ìƒíƒœ ê´€ë¦¬
```javascript
// frontend/src/store/optimizedState.js
export class OptimizedStateManager {
  constructor() {
    this.state = new Map();
    this.listeners = new Map();
    this.mutations = new Map();
    this.actions = new Map();
    this.cache = new Map();
    
    // ìƒíƒœ ë³€ê²½ ë°°ì¹˜ ì²˜ë¦¬
    this.batchQueue = [];
    this.batchTimeout = null;
  }

  // ìƒíƒœ ì„¤ì • (ë°°ì¹˜ ì²˜ë¦¬)
  setState(key, value, immediate = false) {
    if (immediate) {
      this._setStateImmediate(key, value);
    } else {
      this._queueStateUpdate(key, value);
    }
  }

  _queueStateUpdate(key, value) {
    this.batchQueue.push({ key, value });
    
    if (this.batchTimeout) {
      clearTimeout(this.batchTimeout);
    }
    
    this.batchTimeout = setTimeout(() => {
      this._processBatch();
    }, 0);
  }

  _processBatch() {
    const updates = new Map();
    
    // ë°°ì¹˜ ì—…ë°ì´íŠ¸ ë³‘í•©
    this.batchQueue.forEach(({ key, value }) => {
      updates.set(key, value);
    });
    
    // ìƒíƒœ ì—…ë°ì´íŠ¸
    updates.forEach((value, key) => {
      this._setStateImmediate(key, value);
    });
    
    // ë°°ì¹˜ í ì´ˆê¸°í™”
    this.batchQueue = [];
    this.batchTimeout = null;
  }

  _setStateImmediate(key, value) {
    const oldValue = this.state.get(key);
    
    // ê°’ ë³€ê²½ í™•ì¸
    if (this._isEqual(oldValue, value)) {
      return;
    }
    
    this.state.set(key, value);
    
    // ë¦¬ìŠ¤ë„ˆ í˜¸ì¶œ
    const listeners = this.listeners.get(key) || [];
    listeners.forEach(callback => {
      try {
        callback(value, oldValue, key);
      } catch (error) {
        console.error(`State listener error for key "${key}":`, error);
      }
    });
  }

  // ìƒíƒœ êµ¬ë…
  subscribe(key, callback) {
    if (!this.listeners.has(key)) {
      this.listeners.set(key, []);
    }
    
    this.listeners.get(key).push(callback);
    
    // ì¦‰ì‹œ í˜„ì¬ ê°’ í˜¸ì¶œ
    const currentValue = this.state.get(key);
    if (currentValue !== undefined) {
      callback(currentValue, undefined, key);
    }
    
    // êµ¬ë… í•´ì œ í•¨ìˆ˜ ë°˜í™˜
    return () => {
      const listeners = this.listeners.get(key);
      if (listeners) {
        const index = listeners.indexOf(callback);
        if (index > -1) {
          listeners.splice(index, 1);
        }
      }
    };
  }

  // ê¹Šì€ ê°’ ë¹„êµ
  _isEqual(a, b) {
    if (a === b) return true;
    if (a == null || b == null) return false;
    if (typeof a !== typeof b) return false;
    
    if (typeof a === 'object') {
      if (Array.isArray(a) !== Array.isArray(b)) return false;
      
      if (Array.isArray(a)) {
        if (a.length !== b.length) return false;
        return a.every((val, index) => this._isEqual(val, b[index]));
      }
      
      const keysA = Object.keys(a);
      const keysB = Object.keys(b);
      
      if (keysA.length !== keysB.length) return false;
      
      return keysA.every(key => this._isEqual(a[key], b[key]));
    }
    
    return false;
  }

  // ê³„ì‚°ëœ ê°’ (ìºì‹±)
  computed(key, computeFn, dependencies) {
    const cacheKey = `computed:${key}`;
    
    const compute = () => {
      const result = computeFn();
      this.cache.set(cacheKey, result);
      return result;
    };
    
    // ì˜ì¡´ì„± êµ¬ë…
    const unsubscribers = dependencies.map(depKey =>
      this.subscribe(depKey, () => {
        // ì˜ì¡´ì„± ë³€ê²½ ì‹œ ìºì‹œ ë¬´íš¨í™”
        this.cache.delete(cacheKey);
      })
    );
    
    // ì´ˆê¸° ê³„ì‚°
    return compute();
  }
}

export const optimizedState = new OptimizedStateManager();
```

---

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„

### 1. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```javascript
// frontend/src/utils/performanceMonitor.js
export class PerformanceMonitor {
  constructor() {
    this.metrics = new Map();
    this.observers = new Map();
    this.reportQueue = [];
    this.reportInterval = 30000; // 30ì´ˆë§ˆë‹¤ ë¦¬í¬íŠ¸
    
    this.initObservers();
    this.startReporting();
  }

  initObservers() {
    // Core Web Vitals ëª¨ë‹ˆí„°ë§
    this.observeLCP(); // Largest Contentful Paint
    this.observeFID(); // First Input Delay
    this.observeCLS(); // Cumulative Layout Shift
    this.observeTTFB(); // Time to First Byte
  }

  observeLCP() {
    const observer = new PerformanceObserver((list) => {
      const entries = list.getEntries();
      const lastEntry = entries[entries.length - 1];
      
      this.recordMetric('lcp', lastEntry.startTime);
    });
    
    observer.observe({ entryTypes: ['largest-contentful-paint'] });
    this.observers.set('lcp', observer);
  }

  observeFID() {
    const observer = new PerformanceObserver((list) => {
      const entries = list.getEntries();
      entries.forEach(entry => {
        this.recordMetric('fid', entry.processingStart - entry.startTime);
      });
    });
    
    observer.observe({ entryTypes: ['first-input'] });
    this.observers.set('fid', observer);
  }

  observeCLS() {
    let clsValue = 0;
    const observer = new PerformanceObserver((list) => {
      const entries = list.getEntries();
      entries.forEach(entry => {
        if (!entry.hadRecentInput) {
          clsValue += entry.value;
        }
      });
      
      this.recordMetric('cls', clsValue);
    });
    
    observer.observe({ entryTypes: ['layout-shift'] });
    this.observers.set('cls', observer);
  }

  observeTTFB() {
    const observer = new PerformanceObserver((list) => {
      const entries = list.getEntries();
      entries.forEach(entry => {
        if (entry.responseStart > 0) {
          this.recordMetric('ttfb', entry.responseStart - entry.requestStart);
        }
      });
    });
    
    observer.observe({ entryTypes: ['navigation'] });
    this.observers.set('ttfb', observer);
  }

  recordMetric(name, value) {
    const timestamp = Date.now();
    const metric = { name, value, timestamp };
    
    if (!this.metrics.has(name)) {
      this.metrics.set(name, []);
    }
    
    this.metrics.get(name).push(metric);
    
    // íì— ì¶”ê°€
    this.reportQueue.push(metric);
  }

  // ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê¸°ë¡
  measureCustom(name, startTime, endTime) {
    const duration = endTime - startTime;
    this.recordMetric(name, duration);
  }

  // API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
  measureApiCall(url, startTime, endTime) {
    const duration = endTime - startTime;
    this.recordMetric(`api:${url}`, duration);
  }

  // í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì¸¡ì •
  measurePageLoad(pageName, startTime, endTime) {
    const duration = endTime - startTime;
    this.recordMetric(`page:${pageName}`, duration);
  }

  startReporting() {
    setInterval(() => {
      this.reportMetrics();
    }, this.reportInterval);
  }

  async reportMetrics() {
    if (this.reportQueue.length === 0) return;

    const metrics = [...this.reportQueue];
    this.reportQueue = [];

    try {
      await fetch('/api/v1/metrics', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          metrics,
          userAgent: navigator.userAgent,
          url: window.location.href,
          timestamp: Date.now(),
        }),
      });
    } catch (error) {
      console.warn('Failed to report metrics:', error);
      // ì‹¤íŒ¨í•œ ë©”íŠ¸ë¦­ì„ ë‹¤ì‹œ íì— ì¶”ê°€
      this.reportQueue.unshift(...metrics);
    }
  }

  // ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
  generateReport() {
    const report = {
      timestamp: Date.now(),
      url: window.location.href,
      userAgent: navigator.userAgent,
      metrics: {},
      summary: {},
    };

    // ë©”íŠ¸ë¦­ ì§‘ê³„
    this.metrics.forEach((values, name) => {
      const sorted = values.sort((a, b) => a.value - b.value);
      const count = sorted.length;
      
      report.metrics[name] = {
        count,
        min: sorted[0]?.value || 0,
        max: sorted[count - 1]?.value || 0,
        avg: values.reduce((sum, m) => sum + m.value, 0) / count,
        p50: this.percentile(sorted, 0.5),
        p95: this.percentile(sorted, 0.95),
        p99: this.percentile(sorted, 0.99),
      };
    });

    // ìš”ì•½ ìƒì„±
    report.summary = {
      lcp: report.metrics.lcp?.avg || 0,
      fid: report.metrics.fid?.avg || 0,
      cls: report.metrics.cls?.avg || 0,
      ttfb: report.metrics.ttfb?.avg || 0,
    };

    return report;
  }

  percentile(sorted, p) {
    const index = Math.ceil(sorted.length * p) - 1;
    return sorted[index]?.value || 0;
  }

  // ì„±ëŠ¥ íŒíŠ¸ ì œê³µ
  getPerformanceHints() {
    const hints = [];
    const metrics = this.generateReport().metrics;

    if (metrics.lcp?.avg > 2500) {
      hints.push('LCPê°€ 2.5ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.');
    }

    if (metrics.fid?.avg > 100) {
      hints.push('FIDê°€ 100msë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. JavaScript ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.');
    }

    if (metrics.cls?.avg > 0.1) {
      hints.push('CLSê°€ 0.1ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ë ˆì´ì•„ì›ƒ ì‹œí”„íŠ¸ë¥¼ ì¤„ì´ì„¸ìš”.');
    }

    return hints;
  }
}

export const performanceMonitor = new PerformanceMonitor();
```

### 2. ë°±ì—”ë“œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```python
# backend/app/monitoring/performance.py
import time
import psutil
import threading
from functools import wraps
from collections import defaultdict, deque
from prometheus_client import Counter, Histogram, Gauge, generate_latest

# Prometheus ë©”íŠ¸ë¦­
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration', ['method', 'endpoint'])
ACTIVE_CONNECTIONS = Gauge('http_active_connections', 'Active HTTP connections')
MEMORY_USAGE = Gauge('memory_usage_bytes', 'Memory usage in bytes')
CPU_USAGE = Gauge('cpu_usage_percent', 'CPU usage percentage')

class PerformanceMonitor:
    def __init__(self):
        self.request_times = deque(maxlen=1000)
        self.error_count = defaultdict(int)
        self.active_requests = 0
        self.monitoring_thread = None
        self.start_monitoring()
    
    def start_monitoring(self):
        """ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_thread = threading.Thread(target=self._monitor_system, daemon=True)
        self.monitoring_thread.start()
    
    def _monitor_system(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
        while True:
            try:
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                memory = psutil.virtual_memory()
                MEMORY_USAGE.set(memory.used)
                
                # CPU ì‚¬ìš©ë¥ 
                cpu_percent = psutil.cpu_percent()
                CPU_USAGE.set(cpu_percent)
                
                time.sleep(10)  # 10ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
            except Exception as e:
                print(f"Monitoring error: {e}")
                time.sleep(30)
    
    def record_request(self, method, endpoint, status_code, duration):
        """ìš”ì²­ ê¸°ë¡"""
        REQUEST_COUNT.labels(method=method, endpoint=endpoint, status=status_code).inc()
        REQUEST_DURATION.labels(method=method, endpoint=endpoint).observe(duration)
        
        self.request_times.append(duration)
        
        if status_code >= 400:
            self.error_count[f"{method} {endpoint}"] += 1
    
    def get_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        recent_times = list(self.request_times)[-100:]  # ìµœê·¼ 100ê°œ ìš”ì²­
        
        if not recent_times:
            return {}
        
        recent_times.sort()
        n = len(recent_times)
        
        return {
            'request_count': len(self.request_times),
            'active_requests': self.active_requests,
            'error_count': dict(self.error_count),
            'response_time': {
                'min': recent_times[0],
                'max': recent_times[-1],
                'avg': sum(recent_times) / n,
                'p50': recent_times[int(n * 0.5)],
                'p95': recent_times[int(n * 0.95)],
                'p99': recent_times[int(n * 0.99)],
            }
        }

# ì „ì—­ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
performance_monitor = PerformanceMonitor()

def monitor_performance(f):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        start_time = time.time()
        performance_monitor.active_requests += 1
        
        try:
            result = f(*args, **kwargs)
            status_code = 200
            return result
        except Exception as e:
            status_code = 500
            raise
        finally:
            duration = time.time() - start_time
            performance_monitor.active_requests -= 1
            
            # Flask request ê°ì²´ì—ì„œ ì •ë³´ ì¶”ì¶œ
            from flask import request
            method = request.method
            endpoint = request.endpoint or 'unknown'
            
            performance_monitor.record_request(method, endpoint, status_code, duration)
    
    return decorated_function

# ì‚¬ìš© ì˜ˆì‹œ
@api_bp.route('/metrics', methods=['GET'])
def get_prometheus_metrics():
    """Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸"""
    return generate_latest(), 200, {'Content-Type': 'text/plain'}

@api_bp.route('/performance', methods=['GET'])
@monitor_performance
def get_performance_metrics():
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ API"""
    return jsonify(performance_monitor.get_metrics())
```

---

## ğŸ“… ì„±ëŠ¥ ìµœì í™” êµ¬í˜„ ì¼ì •

### Week 1: ë°±ì—”ë“œ ìµœì í™”
- **Day 1**: Gunicorn ì„¤ì • ìµœì í™”, ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„
- **Day 2**: ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”, ì¸ë±ì‹± ê°œì„ 
- **Day 3**: API ì‘ë‹µ ìºì‹±, Redis í†µí•©
- **Day 4**: ë¹„ë™ê¸° ì²˜ë¦¬ êµ¬í˜„, ìŠ¤ë ˆë“œ í’€ ìµœì í™”
- **Day 5**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŠœë‹

### Week 2: í”„ë¡ íŠ¸ì—”ë“œ ìµœì í™”
- **Day 1**: Webpack ë²ˆë“¤ ìµœì í™”, ì½”ë“œ ë¶„í• 
- **Day 2**: ì´ë¯¸ì§€ ìµœì í™”, ì§€ì—° ë¡œë”© êµ¬í˜„
- **Day 3**: ìƒíƒœ ê´€ë¦¬ ìµœì í™”, ë¶ˆí•„ìš”í•œ ë Œë”ë§ ë°©ì§€
- **Day 4**: ë¦¬ì†ŒìŠ¤ í”„ë¦¬ë¡œë”©, ìºì‹± ì „ëµ
- **Day 5**: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ êµ¬í˜„, ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­

### Week 3: í†µí•© ìµœì í™” ë° í…ŒìŠ¤íŠ¸
- **Day 1**: ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- **Day 2**: ë³‘ëª© ì§€ì  ì‹ë³„ ë° í•´ê²°
- **Day 3**: ë¡œë“œ í…ŒìŠ¤íŠ¸ ë° ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸
- **Day 4**: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
- **Day 5**: ìµœì¢… ì„±ëŠ¥ ê²€ì¦ ë° ë¬¸ì„œí™”

---

## ğŸ¯ ì„±ê³µ ì§€í‘œ

### ì‘ë‹µ ì†ë„ ëª©í‘œ
- âœ… **API ì‘ë‹µ**: < 200ms (í‰ê· ), < 500ms (95th percentile)
- âœ… **í˜ì´ì§€ ë¡œë”©**: < 1ì´ˆ (ì´ˆê¸°), < 500ms (SPA ë„¤ë¹„ê²Œì´ì…˜)
- âœ… **AI ì‘ë‹µ**: < 2ì´ˆ (ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘), < 5ì´ˆ (ì™„ì „ ì‘ë‹µ)
- âœ… **ê²€ìƒ‰ ì„±ëŠ¥**: < 100ms (RAG ê²€ìƒ‰)

### ì²˜ë¦¬ëŸ‰ ëª©í‘œ
- âœ… **ë™ì‹œ ì‚¬ìš©ì**: 1000ëª… â†’ 10000ëª…
- âœ… **ìš”ì²­ ì²˜ë¦¬ëŸ‰**: 100 req/s â†’ 1000 req/s
- âœ… **ë©”ëª¨ë¦¬ íš¨ìœ¨**: 50% ê°ì†Œ
- âœ… **CPU íš¨ìœ¨**: 30% ê°œì„ 

### ì‚¬ìš©ì ê²½í—˜ ëª©í‘œ
- âœ… **Core Web Vitals**: ëª¨ë“  ì§€í‘œ "Good" ë“±ê¸‰
- âœ… **ìºì‹œ íˆíŠ¸ìœ¨**: > 80%
- âœ… **ë²ˆë“¤ í¬ê¸°**: < 500KB (ì´ˆê¸° ë¡œë”©)
- âœ… **ì´ë¯¸ì§€ ìµœì í™”**: WebP ì§€ì›, ì§€ì—° ë¡œë”©

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-17  
**ë²„ì „**: 1.0.0  
**ìƒíƒœ**: ğŸ“‹ ê³„íš ì™„ë£Œ, ğŸš€ êµ¬í˜„ ì¤€ë¹„
